# -*- coding: utf-8 -*-
"""Fibrosis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uIMv2GNuyAdCYGlUEDnAwpOJBGINR3C1
"""

#XGBoost for binary classification using all numeric features
import xgboost as xgb
from sklearn.model_selection import GridSearchCV
import pandas as pd
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, auc, classification_report
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.layers import Flatten, Dense, concatenate
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import MinMaxScaler

tsv_file_path = 'Data_SHG_FINAL.tsv'
df = pd.read_csv(tsv_file_path, sep='\t')

# Select columns to use as features
feature_columns = [
    'Red-Transformed', 'Blue-Transformed', 'Green-Transformed', 'Pink-Transformed',
    'All_pixels-Transformed-AROI', 'Pixel_containing_Collagen-Transformed_(Red+Pink)',
    'Number_of_Red_pixel_(Original)', 'Intensity-Mean-Red-Original_(1-254)',
    'Number_of_Green_pixel_(Original)', 'I_cn=Intensity-Mean-Green-Original_(1-254)',
    'Collagen%_Transformed_image_((Red+pink)/Total)',
    'Area_of_Skeleton_All_colors_Transformed', 'Area_of_Skeleton_of_Collagen_(Red+Pink)_Transformed',
    'NBP(Number_of_Branchpoints_of_Collagen)_Transformed',
    'Cn_(No_of_pixels_with_Collagen_(Red+Pink))_Transformed',
    'CA_or_ACn_(Collagen_area_in_um^2)_Transformed',
    'Number_of_unsaturated_pixels_(Green)Aucn', 'Total_Number_of_Pixels_of_Green',
    'Number_of_saturated_green_pixels_(AQ_AP)', 'Intensity_of_Unsaturated_Pixel_UCFD',
    'Intensity_Saturated_Pixel_CFD', 'CAR_(Collagen_Area_Ratio=Collagen%)',
    'CRI_(Collagen_Reticulation_Index)', 'CARD_(Collagen_Area_Reticulation_Density)',
    'Total_Number_of_Collagen_Fibers', 'Median_of_Fiber_Orientation_(Angle)',
    'Median_of_Fiber_Length', 'Median_of_Fiber_Width', 'Long_Fibers', 'Short_Fibers',
    'Thick_Fibers_(Max_Width)', 'Thin_Fibers_(Min_Width)', 'Ratio_of_Long_Fibers',
    'Ratio_of_Short_Fibers', 'Ratio_of_Thick_Fibers', 'Ratio_of_Thin_Fibers'
]

# Separate features (X) and target variable (y)
I = df[feature_columns]
y = df['binary_group']
image_paths = df['image_path']

scaler = MinMaxScaler()
X_normalized = scaler.fit_transform(I)

# Convert class labels to binary matrix using LabelBinarizer
label_binarizer = LabelBinarizer()
y_binary = label_binarizer.fit_transform(y).flatten()

# Preprocess image data
def preprocess_image(image_path, target_size=(224, 224)):
    img = image.load_img(image_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array /= 255.0
    return img_array

images = np.array([preprocess_image(path) for path in image_paths])

# Load the VGG16 model with pretrained weights
vgg_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))
for layer in vgg_model.layers:
    layer.trainable = False
image_features = vgg_model.predict(images)

flattened_image_features = image_features.reshape(image_features.shape[0], -1)

# Concatenate image and numerical features
x = np.concatenate([flattened_image_features, X_normalized], axis=1)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    x, y_binary, test_size=0.2, random_state=42
)

# Train XGBoost model
dtrain = xgb.DMatrix(data=X_train, label=y_train)
dtest = xgb.DMatrix(data=X_test, label=y_test)

param_grid = {
    # 'max_depth': [3, 6, 9],
    'max_depth': [2],
    # 'eta': [0.1, 0.2, 0.3],
    'eta': [0.2],
    # 'subsample': [0.6, 0.8, 1.0],
    'subsample': [0.6],
    # 'colsample_bytree': [0.6, 0.8, 1.0]
    'colsample_bytree': [0.8]
}

# Initialize XGBoost classifier
xgb_model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss')

# Initialize GridSearchCV
grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='neg_log_loss')

# Fit GridSearchCV
grid_search.fit(X_train, y_train)

print("Best Parameters:", grid_search.best_params_)

# Get predicted probabilities
y_pred_prob = grid_search.predict_proba(X_test)[:, 1]

# Compute ROC curve and ROC area for binary classification
fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('Specificity')
plt.ylabel('Sensitivity')
plt.title('XGBoost ROC for binary classification using all features')
plt.legend(loc="lower right")
plt.show()

# Get predicted labels
y_pred = np.round(y_pred_prob)

cm = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(label_binarizer.classes_))
plt.xticks(tick_marks, label_binarizer.classes_, rotation=45)
plt.yticks(tick_marks, label_binarizer.classes_)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')



# Add text annotations
thresh = cm.max() / 2.
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        plt.text(j, i, format(cm[i, j], 'd'),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

plt.tight_layout()
plt.show()


# Print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_binarizer.classes_))

import xgboost as xgb
from sklearn.model_selection import GridSearchCV
import pandas as pd
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, auc, classification_report
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.layers import Flatten, Dense, concatenate
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# Read the Excel spreadsheet
excel_file_path = 'CAR_CFD_UCFD_CRI_CARD.tsv'
column_names = ['CAR', 'CFD', 'UCFD', 'CRI', 'CARD', 'group', 'image_path', 'binary_group']
df = pd.read_csv(excel_file_path, sep='\t', names=column_names)
num_features = df[['CAR', 'CFD', 'UCFD', 'CRI', 'CARD']].values
num_features = num_features[1:]
image_paths = df['image_path'].values
image_paths = image_paths[1:]
y_string = df['binary_group'].values[1:]

# Convert class labels to binary matrix using LabelBinarizer
label_binarizer = LabelBinarizer()
y_binary = label_binarizer.fit_transform(y_string).flatten()

# Preprocess image data
def preprocess_image(image_path, target_size=(224, 224)):
    img = image.load_img(image_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array /= 255.0
    return img_array

images = np.array([preprocess_image(path) for path in image_paths])

# Load the VGG16 model with pretrained weights
vgg_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))
for layer in vgg_model.layers:
    layer.trainable = False
image_features = vgg_model.predict(images)

flattened_image_features = image_features.reshape(image_features.shape[0], -1)

# # Flatten image features
# flattened_image_features = Flatten()(image_features)

# Preprocess numerical data (similar to image preprocessing)
# num_features = num_features.astype(np.float32)
# num_features /= num_features.max(axis=0)

# Concatenate image and numerical features
x = np.concatenate([flattened_image_features, num_features], axis=1)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    x, y_binary, test_size=0.2, random_state=42
)

# Train XGBoost model
dtrain = xgb.DMatrix(data=X_train, label=y_train)
dtest = xgb.DMatrix(data=X_test, label=y_test)

# params = {
#     'max_depth': 6,
#     'eta': 0.3,
#     'objective': 'binary:logistic',
#     'eval_metric': 'logloss',
#     'subsample': 0.8,
#     'colsample_bytree': 0.8
# }

# num_rounds = 100
# xgb_model = xgb.train(params, dtrain, num_rounds, evals=[(dtest, 'eval')], early_stopping_rounds=10)

# Best Parameters: {'colsample_bytree': 0.8, 'eta': 0.2, 'max_depth': 3, 'subsample': 0.6}
# Best Parameters: {'colsample_bytree': 0.8, 'eta': 0.2, 'max_depth': 2, 'subsample': 0.6}

param_grid = {
    # 'max_depth': [3, 6, 9],
    'max_depth': [2],
    # 'eta': [0.1, 0.2, 0.3],
    'eta': [0.2],
    # 'subsample': [0.6, 0.8, 1.0],
    'subsample': [0.6],
    # 'colsample_bytree': [0.6, 0.8, 1.0]
    'colsample_bytree': [0.8]
}

# Initialize XGBoost classifier
xgb_model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss')

# Initialize GridSearchCV
grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='neg_log_loss')

# Fit GridSearchCV
grid_search.fit(X_train, y_train)

print("Best Parameters:", grid_search.best_params_)

# Get predicted probabilities
y_pred_prob = grid_search.predict_proba(X_test)[:, 1]

# Compute ROC curve and ROC area for binary classification
fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('Specificity')
plt.ylabel('Sensitivity')
plt.title('XGBoost ROC for binary classification using 5 features')
plt.legend(loc="lower right")
plt.show()

# Get predicted labels
y_pred = np.round(y_pred_prob)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(label_binarizer.classes_))
plt.xticks(tick_marks, label_binarizer.classes_, rotation=45)
plt.yticks(tick_marks, label_binarizer.classes_)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')


cm = confusion_matrix(y_test, y_pred)

# Add text annotations
thresh = cm.max() / 2.
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        plt.text(j, i, format(cm[i, j], 'd'),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

plt.tight_layout()
plt.show()


# Print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_binarizer.classes_))

import xgboost as xgb
from sklearn.model_selection import GridSearchCV
import pandas as pd
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, auc, classification_report
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.layers import Flatten, Dense, concatenate
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# Read the Excel spreadsheet
excel_file_path = 'CAR_CFD_UCFD_CRI_CARD.tsv'
column_names = ['CAR', 'CFD', 'UCFD', 'CRI', 'CARD', 'group', 'image_path', 'binary_group']
df = pd.read_csv(excel_file_path, sep='\t', names=column_names)
num_features = df[['CAR', 'CFD', 'UCFD', 'CRI', 'CARD']].values
num_features = num_features[1:]
image_paths = df['image_path'].values
image_paths = image_paths[1:]
y_string = df['binary_group'].values[1:]

# Convert class labels to binary matrix using LabelBinarizer
label_binarizer = LabelBinarizer()
y_binary = label_binarizer.fit_transform(y_string).flatten()

# Preprocess image data
def preprocess_image(image_path, target_size=(224, 224)):
    img = image.load_img(image_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array /= 255.0
    return img_array

images = np.array([preprocess_image(path) for path in image_paths])

# Load the VGG16 model with pretrained weights
vgg_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))
for layer in vgg_model.layers:
    layer.trainable = False
image_features = vgg_model.predict(images)

flattened_image_features = image_features.reshape(image_features.shape[0], -1)

# # Flatten image features
# flattened_image_features = Flatten()(image_features)

# Preprocess numerical data (similar to image preprocessing)
# num_features = num_features.astype(np.float32)
# num_features /= num_features.max(axis=0)

# Concatenate image and numerical features
x = np.concatenate([flattened_image_features, num_features], axis=1)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    x, y_binary, test_size=0.2, random_state=42
)

# Train XGBoost model
dtrain = xgb.DMatrix(data=X_train, label=y_train)
dtest = xgb.DMatrix(data=X_test, label=y_test)

# params = {
#     'max_depth': 6,
#     'eta': 0.3,
#     'objective': 'binary:logistic',
#     'eval_metric': 'logloss',
#     'subsample': 0.8,
#     'colsample_bytree': 0.8
# }

# num_rounds = 100
# xgb_model = xgb.train(params, dtrain, num_rounds, evals=[(dtest, 'eval')], early_stopping_rounds=10)

# Best Parameters: {'colsample_bytree': 0.8, 'eta': 0.2, 'max_depth': 3, 'subsample': 0.6}
# Best Parameters: {'colsample_bytree': 0.8, 'eta': 0.2, 'max_depth': 2, 'subsample': 0.6}

param_grid = {
    # 'max_depth': [3, 6, 9],
    'max_depth': [2],
    # 'eta': [0.1, 0.2, 0.3],
    'eta': [0.2],
    # 'subsample': [0.6, 0.8, 1.0],
    'subsample': [0.6],
    # 'colsample_bytree': [0.6, 0.8, 1.0]
    'colsample_bytree': [0.8]
}

# Initialize XGBoost classifier
xgb_model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss')

# Initialize GridSearchCV
grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='neg_log_loss')

# Fit GridSearchCV
grid_search.fit(X_train, y_train)

print("Best Parameters:", grid_search.best_params_)

# Get predicted probabilities
y_pred_prob = grid_search.predict_proba(X_test)[:, 1]

# Compute ROC curve and ROC area for binary classification
fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('Specificity')
plt.ylabel('Sensitivity')
plt.title('XGBoost Receiver Operating Characteristic (ROC) for binary classification')
plt.legend(loc="lower right")
plt.show()

# Get predicted labels
y_pred = np.round(y_pred_prob)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(label_binarizer.classes_))
plt.xticks(tick_marks, label_binarizer.classes_, rotation=45)
plt.yticks(tick_marks, label_binarizer.classes_)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')


cm = confusion_matrix(y_test, y_pred)

# Add text annotations
thresh = cm.max() / 2.
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        plt.text(j, i, format(cm[i, j], 'd'),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

plt.tight_layout()
plt.show()


# Print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_binarizer.classes_))

#GaussianNB model
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, roc_curve, auc
from sklearn.naive_bayes import GaussianNB

# Load your data
excel_file_path = 'CAR_CFD_UCFD_CRI_CARD.tsv'
column_names = ['CAR', 'CFD', 'UCFD', 'CRI', 'CARD', 'group', 'image_path', 'binary_group']
df = pd.read_csv(excel_file_path, sep='\t', names=column_names)
num_features = df[['CAR', 'CFD', 'UCFD', 'CRI', 'CARD']].values
num_features = num_features[1:]
image_paths = df['image_path'].values
image_paths = image_paths[1:]
y_string = df['binary_group'].values[1:]

# Convert class labels to binary matrix using LabelBinarizer
label_binarizer = LabelBinarizer()
y_binary = label_binarizer.fit_transform(y_string).flatten()

# Preprocess image data
def preprocess_image(image_path, target_size=(224, 224)):
    img = image.load_img(image_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array /= 255.0
    return img_array

images = np.array([preprocess_image(path) for path in image_paths])

# Load the VGG16 model with pretrained weights
vgg_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))
for layer in vgg_model.layers:
    layer.trainable = False
image_features = vgg_model.predict(images)

flattened_image_features = image_features.reshape(image_features.shape[0], -1)

# # Flatten image features
# flattened_image_features = Flatten()(image_features)

# Preprocess numerical data (similar to image preprocessing)
# num_features = num_features.astype(np.float32)
# num_features /= num_features.max(axis=0)

# Concatenate image and numerical features
x = np.concatenate([flattened_image_features, num_features], axis=1)




# Number of runs for averaging results
num_runs = 10

# Initialize list to store AUC values for each class
auc_values = [[] for _ in range(len(set(y_string)))]

# Parameters for model training
#random_state = 42

# Loop for multiple runs
# for _ in range(num_runs):
# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(x, y_binary, test_size=0.2, random_state=42)

# Convert class labels to numerical labels
# label_encoder = LabelEncoder()
# y_train_encoded = label_encoder.fit_transform(y_train)
# y_test_encoded = label_encoder.transform(y_test)
# num_classes = len(label_encoder.classes_)

# Create a Naive Bayes classifier
model = GaussianNB()

# Train the model
model.fit(X_train, y_train)

# Predict probabilities for each class
y_pred_prob = model.predict_proba(X_test)[:, 1]

# Compute ROC curve and ROC area for binary classification
fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('Specificity')
plt.ylabel('Sensitivity')
plt.title('GaussianNB Receiver Operating Characteristic (ROC) for binary classification')
plt.legend(loc="lower right")
plt.show()

# Get predicted labels
y_pred = np.round(y_pred_prob)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(label_binarizer.classes_))
plt.xticks(tick_marks, label_binarizer.classes_, rotation=45)
plt.yticks(tick_marks, label_binarizer.classes_)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')


cm = confusion_matrix(y_test, y_pred)

# Add text annotations
thresh = cm.max() / 2.
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        plt.text(j, i, format(cm[i, j], 'd'),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

plt.tight_layout()
plt.show()

# Print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_binarizer.classes_))

# # Calculate mean ROC curve for each class
# mean_fpr_tpr = []
# for class_index in range(num_classes):
#     fpr_values = []
#     tpr_values = []
#     for fpr, tpr in auc_values[class_index]:
#         interp_tpr = np.interp(mean_fpr, fpr, tpr)
#         fpr_values.append(mean_fpr)
#         tpr_values.append(interp_tpr)
#     mean_tpr = np.mean(tpr_values, axis=0)
#     mean_auc = auc(mean_fpr, mean_tpr)
#     mean_fpr_tpr.append((mean_fpr, mean_tpr))


# Plot mean ROC curves for each class
# plt.figure(figsize=(8, 6))
# for class_index, (mean_fpr, mean_tpr) in enumerate(mean_fpr_tpr):
#     mean_auc = auc(mean_fpr, mean_tpr)
#     plt.plot([0] + list(mean_fpr), [0] + list(mean_tpr), lw=2, label='ROC curve for class {} (AUC = {:.2f})'.format(class_index, mean_auc))

# plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
# plt.xlabel('Specificity')
# plt.ylabel('Sensitivity')
# plt.title('ROC curves for each class using GaussianNB')
# plt.legend(loc="lower right")
# plt.show()

# # Initialize an empty array to store binary predictions for each class
# all_pred_binary = []

# # Threshold the predicted probabilities for each class separately
# for class_index in range(num_classes):
#     # Threshold the predicted probabilities to get the predicted labels for the current class
#     y_pred_class_binary = np.argmax(y_pred_prob, axis=1)
#     all_pred_binary.append(y_pred_class_binary)


# # Convert the list of binary predictions to a numpy array
# all_pred_binary = np.array(all_pred_binary)


# # Iterate over each class and plot confusion matrix
# for class_index in range(num_classes):
#     # Filter true and predicted labels for the current class
#     y_true_class = (y_test_encoded == class_index).astype(int)
#     y_pred_class = (y_pred_binary == class_index).astype(int)

#     # Compute confusion matrix
#     cm = confusion_matrix(y_true_class, y_pred_class)

#     # Plot confusion matrix
#     plt.figure(figsize=(4, 4))
#     plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
#     plt.title(f'Confusion Matrix for Class {class_index}')
#     plt.colorbar()

#     # Manually specify tick labels for a 2x2 confusion matrix
#     plt.xticks([0, 1], ['Negative', 'Positive'])
#     plt.yticks([0, 1], ['Negative', 'Positive'])

#     plt.xlabel('Predicted Label')
#     plt.ylabel('True Label')
#     plt.tight_layout()
#     plt.show()

#SVM model
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, roc_curve, auc
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC

# Load your data
excel_file_path = 'CAR_CFD_UCFD_CRI_CARD.tsv'
column_names = ['CAR', 'CFD', 'UCFD', 'CRI', 'CARD', 'group', 'image_path', 'binary_group']
df = pd.read_csv(excel_file_path, sep='\t', names=column_names)
num_features = df[['CAR', 'CFD', 'UCFD', 'CRI', 'CARD']].values
num_features = num_features[1:]
image_paths = df['image_path'].values
image_paths = image_paths[1:]
y_string = df['binary_group'].values[1:]

# Convert class labels to binary matrix using LabelBinarizer
label_binarizer = LabelBinarizer()
y_binary = label_binarizer.fit_transform(y_string).flatten()

# Preprocess image data
def preprocess_image(image_path, target_size=(224, 224)):
    img = image.load_img(image_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array /= 255.0
    return img_array

images = np.array([preprocess_image(path) for path in image_paths])

# Load the VGG16 model with pretrained weights
vgg_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))
for layer in vgg_model.layers:
    layer.trainable = False
image_features = vgg_model.predict(images)

flattened_image_features = image_features.reshape(image_features.shape[0], -1)

# # Flatten image features
# flattened_image_features = Flatten()(image_features)

# Preprocess numerical data (similar to image preprocessing)
# num_features = num_features.astype(np.float32)
# num_features /= num_features.max(axis=0)

# Concatenate image and numerical features
x = np.concatenate([flattened_image_features, num_features], axis=1)




# Number of runs for averaging results
num_runs = 10

# Initialize list to store AUC values for each class
auc_values = [[] for _ in range(len(set(y_string)))]

# Parameters for model training
#random_state = 42

# Loop for multiple runs
# for _ in range(num_runs):
# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(x, y_binary, test_size=0.2, random_state=42)

# Convert class labels to numerical labels
# label_encoder = LabelEncoder()
# y_train_encoded = label_encoder.fit_transform(y_train)
# y_test_encoded = label_encoder.transform(y_test)
# num_classes = len(label_encoder.classes_)

# Create a Naive Bayes classifier
model = SVC(probability=True, random_state=42)

# Train the model
model.fit(X_train, y_train)

# Predict probabilities for each class
y_pred_prob = model.predict_proba(X_test)[:, 1]

# Compute ROC curve and ROC area for binary classification
fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc="lower right")
plt.show()

# Get predicted labels
y_pred = np.round(y_pred_prob)

# Print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_binarizer.classes_))

#Random Forest model
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, roc_curve, auc
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier

# Load your data
excel_file_path = 'CAR_CFD_UCFD_CRI_CARD.tsv'
column_names = ['CAR', 'CFD', 'UCFD', 'CRI', 'CARD', 'group', 'image_path', 'binary_group']
df = pd.read_csv(excel_file_path, sep='\t', names=column_names)
num_features = df[['CAR', 'CFD', 'UCFD', 'CRI', 'CARD']].values
num_features = num_features[1:]
image_paths = df['image_path'].values
image_paths = image_paths[1:]
y_string = df['binary_group'].values[1:]

# Convert class labels to binary matrix using LabelBinarizer
label_binarizer = LabelBinarizer()
y_binary = label_binarizer.fit_transform(y_string).flatten()

# Preprocess image data
def preprocess_image(image_path, target_size=(224, 224)):
    img = image.load_img(image_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array /= 255.0
    return img_array

images = np.array([preprocess_image(path) for path in image_paths])

# Load the VGG16 model with pretrained weights
vgg_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))
for layer in vgg_model.layers:
    layer.trainable = False
image_features = vgg_model.predict(images)

flattened_image_features = image_features.reshape(image_features.shape[0], -1)

x = np.concatenate([flattened_image_features, num_features], axis=1)




# Number of runs for averaging results
num_runs = 10

# Initialize list to store AUC values for each class
auc_values = [[] for _ in range(len(set(y_string)))]

# Parameters for model training
#random_state = 42

# Loop for multiple runs
# for _ in range(num_runs):
# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(x, y_binary, test_size=0.2, random_state=42)

# Convert class labels to numerical labels
# label_encoder = LabelEncoder()
# y_train_encoded = label_encoder.fit_transform(y_train)
# y_test_encoded = label_encoder.transform(y_test)
# num_classes = len(label_encoder.classes_)

# Create a Naive Bayes classifier
model = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the model
model.fit(X_train, y_train)

# Predict probabilities for each class
y_pred_prob = model.predict_proba(X_test)[:, 1]

# Compute ROC curve and ROC area for binary classification
fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('Specificity')
plt.ylabel('Sensitivity')
plt.title('RandomForest Receiver Operating Characteristic (ROC) for binary classification')
plt.legend(loc="lower right")
plt.show()

# Get predicted labels
y_pred = np.round(y_pred_prob)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(label_binarizer.classes_))
plt.xticks(tick_marks, label_binarizer.classes_, rotation=45)
plt.yticks(tick_marks, label_binarizer.classes_)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')


cm = confusion_matrix(y_test, y_pred)

# Add text annotations
thresh = cm.max() / 2.
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        plt.text(j, i, format(cm[i, j], 'd'),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

plt.tight_layout()
plt.show()

# Print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_binarizer.classes_))

#Random Forest
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelBinarizer
from sklearn.metrics import confusion_matrix, roc_curve, auc
from sklearn.ensemble import RandomForestClassifier
import pickle

# Load your data
excel_file_path = 'CAR_CFD_UCFD_CRI_CARD.tsv'
column_names = ['CAR', 'CFD', 'UCFD', 'CRI', 'CARD', 'group', 'image_path', 'binary_group']
df = pd.read_csv(excel_file_path, sep='\t', names=column_names)
num_features = df[['CAR', 'CFD', 'UCFD', 'CRI', 'CARD']].values
num_features = num_features[1:]
image_paths = df['image_path'].values
image_paths = image_paths[1:]
y_string = df['group'].values[1:]

# # Convert class labels to binary matrix using LabelBinarizer
# label_binarizer = LabelBinarizer()
# y_binary = label_binarizer.fit_transform(y_string).flatten()

# Preprocess image data
def preprocess_image(image_path, target_size=(224, 224)):
    img = image.load_img(image_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array /= 255.0
    return img_array

images = np.array([preprocess_image(path) for path in image_paths])

# Load the VGG16 model with pretrained weights
vgg_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))
for layer in vgg_model.layers:
    layer.trainable = False
image_features = vgg_model.predict(images)

flattened_image_features = image_features.reshape(image_features.shape[0], -1)

x = np.concatenate([flattened_image_features, num_features], axis=1)

# Number of runs for averaging results
num_runs = 10

# Initialize list to store AUC values for each class
auc_values = [[] for _ in range(len(set(y_string)))]

# Parameters for model training
random_state = 42

# Loop for multiple runs
for _ in range(num_runs):
    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(x, y_string, test_size=0.3, stratify=y_string, random_state=random_state)

    # Convert class labels to binary matrix using LabelBinarizer
    label_binarizer = LabelBinarizer()
    y_train_binary = label_binarizer.fit_transform(y_train)
    y_test_binary = label_binarizer.transform(y_test)

    # Create a separate binary classifier for each class
    models = []
    all_pred_probs = []  # List to store predicted probabilities for each class
    for class_index in range(y_train_binary.shape[1]):
        # Create a Random Forest Classifier model
        model = RandomForestClassifier(n_estimators=100, random_state=random_state)

        # Train the model
        model.fit(X_train, y_train_binary[:, class_index])

        with open('RandomForest_model.pkl', 'wb') as model_file:
          pickle.dump(model, model_file)

        # Add the trained model to the list
        models.append(model)

        # Predict probabilities for the positive class
        y_pred_prob = model.predict_proba(X_test)[:, 1]

        # Append predicted probabilities to the list
        all_pred_probs.append(y_pred_prob)

        # Calculate ROC curve and AUC for the positive class
        fpr, tpr, _ = roc_curve(y_test_binary[:, class_index], y_pred_prob)
        roc_auc = auc(fpr, tpr)
        auc_values[class_index].append((fpr, tpr))
        print(f"Class {class_index}: ROC AUC = {roc_auc:.2f}")

    # Convert list of predicted probabilities to a numpy array
    all_pred_probs = np.array(all_pred_probs)

# Calculate mean ROC curve for each class
mean_fpr_tpr = []
for class_index in range(len(auc_values)):
    fpr_values = [fpr for fpr, _ in auc_values[class_index]]
    tpr_values = [tpr for _, tpr in auc_values[class_index]]
    mean_fpr = np.mean(fpr_values, axis=0)
    mean_tpr = np.mean(tpr_values, axis=0)
    mean_fpr_tpr.append((mean_fpr, mean_tpr))

# Plot mean ROC curves for each class
plt.figure(figsize=(8, 6))
for class_index, (mean_fpr, mean_tpr) in enumerate(mean_fpr_tpr):
    mean_auc = auc(mean_fpr, mean_tpr)
    plt.plot(mean_fpr, mean_tpr, lw=2, label='ROC curve for class {} (AUC = {:.2f})'.format(class_index, mean_auc))

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('Specificity')
plt.ylabel('Sensitivity')
plt.title('ROC curves for multiple classes using Random Forest')
plt.legend(loc="lower right")
plt.show()


# Initialize an empty array to store binary predictions for each class
all_pred_binary = []

# Threshold the predicted probabilities for each class separately
for class_index in range(y_train_binary.shape[1]):
    # Threshold the predicted probabilities to get the predicted labels for the current class
    y_pred_class_binary = (all_pred_probs[class_index] > 0.5).astype(int)
    all_pred_binary.append(y_pred_class_binary)

# Convert the list of binary predictions to a numpy array
all_pred_binary = np.array(all_pred_binary)



# Iterate over each class and plot confusion matrix
for class_index in range(y_test_binary.shape[1]):
    y_true_binary = y_test_binary[:, class_index]    # True labels for current class
    y_pred_binary = all_pred_binary[class_index]     # Predicted labels for current class

    # Compute confusion matrix
    cm = confusion_matrix(y_true_binary, y_pred_binary)

    # Plot confusion matrix
    plt.figure(figsize=(4, 4))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(f'Confusion Matrix for Class {class_index}')
    plt.colorbar()

    # Manually specify tick labels for a 2x2 confusion matrix
    plt.xticks([0, 1], ['Negative', 'Positive'])
    plt.yticks([0, 1], ['Negative', 'Positive'])

    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.tight_layout()
    plt.show()

#SVC NEW
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelBinarizer
from sklearn.metrics import confusion_matrix, roc_curve, auc
from sklearn.svm import SVC
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import VGG16
import pickle

# Load your data
excel_file_path = 'CAR_CFD_UCFD_CRI_CARD.tsv'
column_names = ['CAR', 'CFD', 'UCFD', 'CRI', 'CARD', 'group', 'image_path', 'binary_group']
df = pd.read_csv(excel_file_path, sep='\t', names=column_names)
num_features = df[['CAR', 'CFD', 'UCFD', 'CRI', 'CARD']].values
num_features = num_features[1:]
image_paths = df['image_path'].values
image_paths = image_paths[1:]
y_string = df['group'].values[1:]

# Preprocess image data
def preprocess_image(image_path, target_size=(224, 224)):
    img = image.load_img(image_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array /= 255.0
    return img_array

images = np.array([preprocess_image(path) for path in image_paths])

# Load the VGG16 model with pretrained weights
vgg_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))
for layer in vgg_model.layers:
    layer.trainable = False
image_features = vgg_model.predict(images)

flattened_image_features = image_features.reshape(image_features.shape[0], -1)

X = np.concatenate([flattened_image_features, num_features], axis=1)



# Number of runs for averaging results
num_runs = 10

# Initialize list to store AUC values for each class
auc_values = [[] for _ in range(len(set(y_string)))]

# Parameters for model training
random_state = 42

# Loop for multiple runs
for _ in range(num_runs):
    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y_string, test_size=0.3, stratify=y_string, random_state=random_state)

    # Convert class labels to binary matrix using LabelBinarizer
    label_binarizer = LabelBinarizer()
    y_train_binary = label_binarizer.fit_transform(y_train)
    y_test_binary = label_binarizer.transform(y_test)

    # Create a separate binary classifier for each class
    models = []
    all_pred_probs = []  # List to store predicted probabilities for each class
    for class_index in range(y_train_binary.shape[1]):
        # Create a Random Forest Classifier model
        model = SVC(probability=True, random_state=random_state)

        # Train the model
        model.fit(X_train, y_train_binary[:, class_index])

        with open('SVM_model.pkl', 'wb') as model_file:
          pickle.dump(model, model_file)

        # Add the trained model to the list
        models.append(model)

        # Predict probabilities for the positive class
        y_pred_prob = model.predict_proba(X_test)[:, 1]

        # Append predicted probabilities to the list
        all_pred_probs.append(y_pred_prob)

        # Calculate ROC curve and AUC for the positive class
        fpr, tpr, _ = roc_curve(y_test_binary[:, class_index], y_pred_prob)
        roc_auc = auc(fpr, tpr)
        auc_values[class_index].append((fpr, tpr))
        print(f"Class {class_index}: ROC AUC = {roc_auc:.2f}")

    # Convert list of predicted probabilities to a numpy array
    all_pred_probs = np.array(all_pred_probs)

# Calculate mean ROC curve for each class
mean_fpr_tpr = []
for class_index in range(len(auc_values)):
    fpr_values = [fpr for fpr, _ in auc_values[class_index]]
    tpr_values = [tpr for _, tpr in auc_values[class_index]]
    mean_fpr = np.mean(fpr_values, axis=0)
    mean_tpr = np.mean(tpr_values, axis=0)
    mean_fpr_tpr.append((mean_fpr, mean_tpr))

# Plot mean ROC curves for each class
plt.figure(figsize=(8, 6))
for class_index, (mean_fpr, mean_tpr) in enumerate(mean_fpr_tpr):
    mean_auc = auc(mean_fpr, mean_tpr)
    plt.plot(mean_fpr, mean_tpr, lw=2, label='ROC curve for class {} (AUC = {:.2f})'.format(class_index, mean_auc))

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('Specificity')
plt.ylabel('Sensitivity')
plt.title('ROC curves for multiple classes using SVM')
plt.legend(loc="lower right")
plt.show()


# Initialize an empty array to store binary predictions for each class
all_pred_binary = []

# Threshold the predicted probabilities for each class separately
for class_index in range(y_train_binary.shape[1]):
    # Threshold the predicted probabilities to get the predicted labels for the current class
    y_pred_class_binary = (all_pred_probs[class_index] > 0.5).astype(int)
    all_pred_binary.append(y_pred_class_binary)

# Convert the list of binary predictions to a numpy array
all_pred_binary = np.array(all_pred_binary)



# Iterate over each class and plot confusion matrix
for class_index in range(y_test_binary.shape[1]):
    y_true_binary = y_test_binary[:, class_index]    # True labels for current class
    y_pred_binary = all_pred_binary[class_index]     # Predicted labels for current class

    # Compute confusion matrix
    cm = confusion_matrix(y_true_binary, y_pred_binary)

    # Plot confusion matrix
    plt.figure(figsize=(4, 4))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(f'Confusion Matrix for Class {class_index}')
    plt.colorbar()

    # Manually specify tick labels for a 2x2 confusion matrix
    plt.xticks([0, 1], ['Negative', 'Positive'])
    plt.yticks([0, 1], ['Negative', 'Positive'])

    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.tight_layout()
    plt.show()

#XGBoost Model NEW
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelBinarizer
from sklearn.metrics import confusion_matrix, roc_curve, auc
from xgboost import XGBClassifier
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import VGG16
import pickle

# Load your data
excel_file_path = 'CAR_CFD_UCFD_CRI_CARD.tsv'
column_names = ['CAR', 'CFD', 'UCFD', 'CRI', 'CARD', 'group', 'image_path', 'binary_group']
df = pd.read_csv(excel_file_path, sep='\t', names=column_names)
num_features = df[['CAR', 'CFD', 'UCFD', 'CRI', 'CARD']].values
num_features = num_features[1:]
image_paths = df['image_path'].values
image_paths = image_paths[1:]
y_string = df['group'].values[1:]

# Preprocess image data
def preprocess_image(image_path, target_size=(224, 224)):
    img = image.load_img(image_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array /= 255.0
    return img_array

images = np.array([preprocess_image(path) for path in image_paths])

# Load the VGG16 model with pretrained weights
vgg_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))
for layer in vgg_model.layers:
    layer.trainable = False
image_features = vgg_model.predict(images)

flattened_image_features = image_features.reshape(image_features.shape[0], -1)

X = np.concatenate([flattened_image_features, num_features], axis=1)



# Number of runs for averaging results
num_runs = 10

# Initialize list to store AUC values for each class
auc_values = [[] for _ in range(len(set(y_string)))]

# Parameters for model training
random_state = 42

# Loop for multiple runs
for _ in range(num_runs):
    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y_string, test_size=0.3, stratify=y_string, random_state=random_state)

    # Convert class labels to binary matrix using LabelBinarizer
    label_binarizer = LabelBinarizer()
    y_train_binary = label_binarizer.fit_transform(y_train)
    y_test_binary = label_binarizer.transform(y_test)

    # Create a separate binary classifier for each class
    models = []
    all_pred_probs = []  # List to store predicted probabilities for each class
    for class_index in range(y_train_binary.shape[1]):
        # Create a Random Forest Classifier model
        model = XGBClassifier(random_state=random_state)

        # Train the model
        model.fit(X_train, y_train_binary[:, class_index])


        # Add the trained model to the list
        models.append(model)

        # Predict probabilities for the positive class
        y_pred_prob = model.predict_proba(X_test)[:, 1]

        # Append predicted probabilities to the list
        all_pred_probs.append(y_pred_prob)

        # Calculate ROC curve and AUC for the positive class
        fpr, tpr, _ = roc_curve(y_test_binary[:, class_index], y_pred_prob)
        roc_auc = auc(fpr, tpr)
        auc_values[class_index].append((fpr, tpr))
        print(f"Class {class_index}: ROC AUC = {roc_auc:.2f}")

    # Convert list of predicted probabilities to a numpy array
    all_pred_probs = np.array(all_pred_probs)

with open('XGB_model.pkl', 'wb') as model_file:
          pickle.dump(model, model_file)

# Calculate mean ROC curve for each class
mean_fpr_tpr = []
for class_index in range(len(auc_values)):
    fpr_values = [fpr for fpr, _ in auc_values[class_index]]
    tpr_values = [tpr for _, tpr in auc_values[class_index]]
    mean_fpr = np.mean(fpr_values, axis=0)
    mean_tpr = np.mean(tpr_values, axis=0)
    mean_fpr_tpr.append((mean_fpr, mean_tpr))


# Plot mean ROC curves for each class
plt.figure(figsize=(8, 6))
for class_index, (mean_fpr, mean_tpr) in enumerate(mean_fpr_tpr):
    mean_auc = auc(mean_fpr, mean_tpr)
    plt.plot(mean_fpr, mean_tpr, lw=2, label='ROC curve for class {} (AUC = {:.2f})'.format(class_index, mean_auc))

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('Specificity')
plt.ylabel('Sensitivity')
plt.title('ROC curves for multiple classes using XGBoost')
plt.legend(loc="lower right")
plt.show()


# Initialize an empty array to store binary predictions for each class
all_pred_binary = []

# Threshold the predicted probabilities for each class separately
for class_index in range(y_train_binary.shape[1]):
    # Threshold the predicted probabilities to get the predicted labels for the current class
    y_pred_class_binary = (all_pred_probs[class_index] > 0.5).astype(int)
    all_pred_binary.append(y_pred_class_binary)

# Convert the list of binary predictions to a numpy array
all_pred_binary = np.array(all_pred_binary)



# Iterate over each class and plot confusion matrix
for class_index in range(y_test_binary.shape[1]):
    y_true_binary = y_test_binary[:, class_index]    # True labels for current class
    y_pred_binary = all_pred_binary[class_index]     # Predicted labels for current class

    # Compute confusion matrix
    cm = confusion_matrix(y_true_binary, y_pred_binary)

    # Plot confusion matrix
    plt.figure(figsize=(4, 4))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(f'Confusion Matrix for Class {class_index}')
    plt.colorbar()

    # Manually specify tick labels for a 2x2 confusion matrix
    plt.xticks([0, 1], ['Negative', 'Positive'])
    plt.yticks([0, 1], ['Negative', 'Positive'])

    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.tight_layout()
    plt.show()

#XGBoost Model
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, roc_curve, auc
from xgboost import XGBClassifier
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import VGG16
import pickle

# Load your data
excel_file_path = 'CAR_CFD_UCFD_CRI_CARD.tsv'
column_names = ['CAR', 'CFD', 'UCFD', 'CRI', 'CARD', 'group', 'image_path', 'binary_group']
df = pd.read_csv(excel_file_path, sep='\t', names=column_names)
num_features = df[['CAR', 'CFD', 'UCFD', 'CRI', 'CARD']].values
num_features = num_features[1:]
image_paths = df['image_path'].values
image_paths = image_paths[1:]
y_string = df['group'].values[1:]

# # Convert class labels to binary matrix using LabelBinarizer
# label_binarizer = LabelBinarizer()
# y_binary = label_binarizer.fit_transform(y_string).flatten()

# Preprocess image data
def preprocess_image(image_path, target_size=(224, 224)):
    img = image.load_img(image_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array /= 255.0
    return img_array

images = np.array([preprocess_image(path) for path in image_paths])

# Load the VGG16 model with pretrained weights
vgg_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))
for layer in vgg_model.layers:
    layer.trainable = False
image_features = vgg_model.predict(images)

flattened_image_features = image_features.reshape(image_features.shape[0], -1)

X = np.concatenate([flattened_image_features, num_features], axis=1)

# Number of runs for averaging results
num_runs = 10

# Initialize list to store AUC values for each class
auc_values = [[] for _ in range(len(set(y_string)))]

# Parameters for model training
random_state = 42

# Loop for multiple runs
for _ in range(num_runs):
    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y_string, test_size=0.3, stratify=y_string, random_state=random_state)

    # Convert class labels to numerical labels
    label_encoder = LabelEncoder()
    y_train_encoded = label_encoder.fit_transform(y_train)
    y_test_encoded = label_encoder.transform(y_test)
    num_classes = len(label_encoder.classes_)

    # Create an XGBoost model
    model = XGBClassifier(random_state=random_state)

    # Train the model
    model.fit(X_train, y_train_encoded)

    # Save the trained model
    with open('xgboost_model.pkl', 'wb') as model_file:
        pickle.dump(model, model_file)

    # Predict probabilities for each class
    y_pred_prob = model.predict_proba(X_test)

    # Calculate ROC curve and AUC for each class
    for class_index in range(num_classes):
        y_true_binary_class = (y_test_encoded == class_index).astype(int)
        y_pred_prob_class = y_pred_prob[:, class_index]
        fpr, tpr, _ = roc_curve(y_true_binary_class, y_pred_prob_class)
        roc_auc = auc(fpr, tpr)
        auc_values[class_index].append((fpr, tpr))
        print(f"Class {class_index}: ROC AUC = {roc_auc:.2f}")

# Calculate mean ROC curve for each class
# mean_fpr_tpr = []
# for class_index in range(num_classes):
#     fpr_values = []
#     tpr_values = []
#     for fpr, tpr in auc_values[class_index]:
#         interp_tpr = np.interp(mean_fpr, fpr, tpr)
#         fpr_values.append(mean_fpr)
#         tpr_values.append(interp_tpr)
#     mean_tpr = np.mean(tpr_values, axis=0)
#     mean_auc = auc(mean_fpr, mean_tpr)
#     mean_fpr_tpr.append((mean_fpr, mean_tpr))
mean_fpr_tpr = []
for class_index in range(len(auc_values)):
    fpr_values = [fpr for fpr, _ in auc_values[class_index]]
    tpr_values = [tpr for _, tpr in auc_values[class_index]]
    mean_fpr = np.mean(fpr_values, axis=0)
    mean_tpr = np.mean(tpr_values, axis=0)
    mean_fpr_tpr.append((mean_fpr, mean_tpr))

# Plot mean ROC curves for each class
plt.figure(figsize=(8, 6))
for class_index, (mean_fpr, mean_tpr) in enumerate(mean_fpr_tpr):
    mean_auc = auc(mean_fpr, mean_tpr)
    plt.plot([0] + list(mean_fpr), [0] + list(mean_tpr), lw=2, label='ROC curve for class {} (AUC = {:.2f})'.format(class_index, mean_auc))

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('Specificity')
plt.ylabel('Sensitivity')
plt.title('ROC curves for each class using XGBoost')
plt.legend(loc="lower right")
plt.show()

# Initialize an empty array to store binary predictions for each class
all_pred_binary = []

# Threshold the predicted probabilities for each class separately
for class_index in range(num_classes):
    # Threshold the predicted probabilities to get the predicted labels for the current class
    y_pred_class_binary = np.argmax(y_pred_prob, axis=1)
    all_pred_binary.append(y_pred_class_binary)

# Convert the list of binary predictions to a numpy array
all_pred_binary = np.array(all_pred_binary)

# # Iterate over each class and plot confusion matrix
# for class_index in range(num_classes):
#     # Filter true and predicted labels for the current class
#     y_true_class = (y_test_encoded == class_index).astype(int)
#     y_pred_class = (y_pred_binary == class_index).astype(int)

#     # Compute confusion matrix
#     cm = confusion_matrix(y_true_class, y_pred_class)

#     # Plot confusion matrix
#     plt.figure(figsize=(4, 4))
#     plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
#     plt.title(f'Confusion Matrix for Class {class_index}')
#     plt.colorbar()

#     # Manually specify tick labels for a 2x2 confusion matrix
#     plt.xticks([0, 1], ['Negative', 'Positive'])
#     plt.yticks([0, 1], ['Negative', 'Positive'])

#     plt.xlabel('Predicted Label')
#     plt.ylabel('True Label')
#     plt.tight_layout()
#     plt.show()


# Iterate over each class and plot confusion matrix
for class_index in range(y_test_binary.shape[1]):
    y_true_binary = y_test_binary[:, class_index]    # True labels for current class
    y_pred_binary = all_pred_binary[class_index]     # Predicted labels for current class

    # Compute confusion matrix
    cm = confusion_matrix(y_true_binary, y_pred_binary)

    # Plot confusion matrix
    plt.figure(figsize=(4, 4))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(f'Confusion Matrix for Class {class_index}')
    plt.colorbar()

    # Manually specify tick labels for a 2x2 confusion matrix
    plt.xticks([0, 1], ['Negative', 'Positive'])
    plt.yticks([0, 1], ['Negative', 'Positive'])

    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.tight_layout()
    plt.show()

#GaussianNB model
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, roc_curve, auc
from sklearn.naive_bayes import GaussianNB
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import VGG16

# Load your data
excel_file_path = 'CAR_CFD_UCFD_CRI_CARD.tsv'
column_names = ['CAR', 'CFD', 'UCFD', 'CRI', 'CARD', 'group', 'image_path', 'binary_group']
df = pd.read_csv(excel_file_path, sep='\t', names=column_names)
num_features = df[['CAR', 'CFD', 'UCFD', 'CRI', 'CARD']].values
num_features = num_features[1:]
image_paths = df['image_path'].values
image_paths = image_paths[1:]
y_string = df['group'].values[1:]

# Preprocess image data
def preprocess_image(image_path, target_size=(224, 224)):
    img = image.load_img(image_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array /= 255.0
    return img_array

images = np.array([preprocess_image(path) for path in image_paths])

# Load the VGG16 model with pretrained weights
vgg_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))
for layer in vgg_model.layers:
    layer.trainable = False
image_features = vgg_model.predict(images)

flattened_image_features = image_features.reshape(image_features.shape[0], -1)

X = np.concatenate([flattened_image_features, num_features], axis=1)

# Number of runs for averaging results
num_runs = 10

# Initialize list to store AUC values for each class
auc_values = [[] for _ in range(len(set(y_string)))]

# Parameters for model training
random_state = 42

# Loop for multiple runs
for _ in range(num_runs):
    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y_string, test_size=0.3, stratify=y_string, random_state=random_state)

    # Convert class labels to numerical labels
    label_encoder = LabelEncoder()
    y_train_encoded = label_encoder.fit_transform(y_train)
    y_test_encoded = label_encoder.transform(y_test)
    num_classes = len(label_encoder.classes_)

    # Create a Naive Bayes classifier
    model = GaussianNB()

    # Train the model
    model.fit(X_train, y_train_encoded)

    # Predict probabilities for each class
    y_pred_prob = model.predict_proba(X_test)

    # Calculate ROC curve and AUC for each class
    for class_index in range(num_classes):
        y_true_binary_class = (y_test_encoded == class_index).astype(int)
        y_pred_prob_class = y_pred_prob[:, class_index]
        fpr, tpr, _ = roc_curve(y_true_binary_class, y_pred_prob_class)
        roc_auc = auc(fpr, tpr)
        auc_values[class_index].append((fpr, tpr))
        print(f"Class {class_index}: ROC AUC = {roc_auc:.2f}")

# Calculate mean ROC curve for each class
mean_fpr_tpr = []
for class_index in range(num_classes):
    fpr_values = []
    tpr_values = []
    for fpr, tpr in auc_values[class_index]:
        fpr_values.append(fpr)
        tpr_values.append(tpr)
    mean_fpr = np.mean(fpr_values, axis=0)
    mean_tpr = np.mean(tpr_values, axis=0)
    mean_fpr_tpr.append((mean_fpr, mean_tpr))


# Plot mean ROC curves for each class
plt.figure(figsize=(8, 6))
for class_index, (mean_fpr, mean_tpr) in enumerate(mean_fpr_tpr):
    mean_auc = auc(mean_fpr, mean_tpr)
    plt.plot([0] + list(mean_fpr), [0] + list(mean_tpr), lw=2, label='ROC curve for class {} (AUC = {:.2f})'.format(class_index, mean_auc))

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('Specificity')
plt.ylabel('Sensitivity')
plt.title('ROC curves for multiple classes using GaussianNB')
plt.legend(loc="lower right")
plt.show()

# Initialize an empty array to store binary predictions for each class
all_pred_binary = []

# Threshold the predicted probabilities for each class separately
for class_index in range(num_classes):
    # Threshold the predicted probabilities to get the predicted labels for the current class
    y_pred_class_binary = np.argmax(y_pred_prob, axis=1)
    all_pred_binary.append(y_pred_class_binary)


# Convert the list of binary predictions to a numpy array
all_pred_binary = np.array(all_pred_binary)


# Iterate over each class and plot confusion matrix
for class_index in range(num_classes):
    # Filter true and predicted labels for the current class
    y_true_class = (y_test_encoded == class_index).astype(int)
    y_pred_class = (all_pred_binary[class_index] == class_index).astype(int)

    # Compute confusion matrix
    cm = confusion_matrix(y_true_class, y_pred_class)

    # Plot confusion matrix
    plt.figure(figsize=(4, 4))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(f'Confusion Matrix for Class {class_index}')
    plt.colorbar()

    # Manually specify tick labels for a 2x2 confusion matrix
    plt.xticks([0, 1], ['Negative', 'Positive'])
    plt.yticks([0, 1], ['Negative', 'Positive'])

    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.tight_layout()
    plt.show()

#CNN model
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, roc_curve, auc
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import VGG16
from sklearn.preprocessing import LabelBinarizer

# Load your data
excel_file_path = 'CAR_CFD_UCFD_CRI_CARD.tsv'
column_names = ['CAR', 'CFD', 'UCFD', 'CRI', 'CARD', 'group', 'image_path', 'binary_group']
df = pd.read_csv(excel_file_path, sep='\t', names=column_names)
num_features = df[['CAR', 'CFD', 'UCFD', 'CRI', 'CARD']].values
num_features = num_features[1:]
image_paths = df['image_path'].values
image_paths = image_paths[1:]
y_string = df['group'].values[1:]

# Preprocess image data
def preprocess_image(image_path, target_size=(224, 224)):
    img = image.load_img(image_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array /= 255.0
    return img_array

images = np.array([preprocess_image(path) for path in image_paths])

# Load the VGG16 model with pretrained weights
vgg_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))
for layer in vgg_model.layers:
    layer.trainable = False
image_features = vgg_model.predict(images)

flattened_image_features = image_features.reshape(image_features.shape[0], -1)
X = np.concatenate([flattened_image_features, num_features], axis=1)

# num_flattened_image_features = np.prod(image_features.shape[1:])  # Product of dimensions excluding samples
# print("Number of flattened image features:", num_flattened_image_features)
# X = np.concatenate([image_features.reshape(image_features.shape[0], -1), num_features], axis=1)



# Number of runs for averaging results
num_runs = 10

# Initialize list to store AUC values for each class
auc_values = [[] for _ in range(len(set(y_string)))]

# Parameters for model training
random_state = 42

# Reshape X for CNN input (assuming you want to treat each feature as a channel)
#X = X.reshape(X.shape[0], 1, 5, 1)

# Loop for multiple runs
for _ in range(num_runs):
    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y_string, test_size=0.3, stratify=y_string, random_state=random_state)

    # Convert class labels to numerical labels
    label_encoder = LabelEncoder()
    y_train_encoded = label_encoder.fit_transform(y_train)
    y_test_encoded = label_encoder.transform(y_test)
    num_classes = len(label_encoder.classes_)

    # Create a CNN model
    model = Sequential()
    model.add(Dense(128, activation='relu', input_shape=(25093,)))
    model.add(Dense(128, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(4, activation='softmax'))  # Use softmax activation for multi-class classification

    # Compile the model
    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # Use sparse categorical crossentropy for multi-class classification

    # # Train the model
    # model.fit(X_train, y_train_encoded, batch_size=32, epochs=10, verbose=0)

    # model.save('CNN_model.h5')

    # # Predict probabilities for each class
    # y_pred_prob = model.predict(X_test)
    #all_pred_probs = []
    # Calculate ROC curve and AUC for each class
    for class_index in range(num_classes):
        # Train the model
        model.fit(X_train, y_train_encoded, batch_size=32, epochs=10, verbose=0)

        model.save('CNN_model.h5')

        # Predict probabilities for each class
        y_pred_prob = model.predict(X_test)
        #all_pred_probs.append(y_pred_prob)

        y_true_binary_class = (y_test_encoded == class_index).astype(int)
        y_pred_prob_class = y_pred_prob[:, class_index]
        fpr, tpr, _ = roc_curve(y_true_binary_class, y_pred_prob_class)
        roc_auc = auc(fpr, tpr)
        auc_values[class_index].append((fpr, tpr))
        print(f"Class {class_index}: ROC AUC = {roc_auc:.2f}")

    # # Convert list of predicted probabilities to a numpy array
    # all_pred_probs = np.array(all_pred_probs)

# Calculate mean ROC curve for each class
# mean_fpr_tpr = []
# for class_index in range(num_classes):
#     fpr_values = []
#     tpr_values = []
#     for fpr, tpr in auc_values[class_index]:
#         interp_tpr = np.interp(mean_fpr, fpr, tpr)
#         fpr_values.append(mean_fpr)
#         tpr_values.append(interp_tpr)
#     mean_tpr = np.mean(tpr_values, axis=0)
#     mean_auc = auc(mean_fpr, mean_tpr)
#     mean_fpr_tpr.append((mean_fpr, mean_tpr))

# # Calculate mean ROC curve for each class
# mean_fpr_tpr = []
# for class_index in range(num_classes):
#     fpr_values = []
#     tpr_values = []
#     for fpr, tpr in auc_values[class_index]:
#         fpr_values.append(fpr)
#         tpr_values.append(tpr)
#     mean_fpr = np.mean(fpr_values, axis=0)
#     mean_tpr = np.mean(tpr_values, axis=0)
#     mean_fpr_tpr.append((mean_fpr, mean_tpr))

# Calculate mean ROC curve for each class
mean_fpr_tpr = []
for class_index in range(num_classes):
    fpr_values = []
    tpr_values = []
    max_len = 0  # Track the maximum length of FPR and TPR values among all runs
    for fpr, tpr in auc_values[class_index]:
        fpr_values.append(fpr)
        tpr_values.append(tpr)
        max_len = max(max_len, len(fpr), len(tpr))

    # Interpolate FPR and TPR values for each run to ensure they have the same length
    interp_fpr_values = [np.interp(np.linspace(0, 1, max_len), tpr, fpr) for fpr, tpr in zip(fpr_values, tpr_values)]
    interp_tpr_values = [np.interp(np.linspace(0, 1, max_len), tpr, tpr) for tpr in tpr_values]

    # Calculate mean FPR and TPR
    mean_fpr = np.mean(interp_fpr_values, axis=0)
    mean_tpr = np.mean(interp_tpr_values, axis=0)

    mean_fpr_tpr.append((mean_fpr, mean_tpr))



# Plot mean ROC curves for each class
plt.figure(figsize=(8, 6))
for class_index, (mean_fpr, mean_tpr) in enumerate(mean_fpr_tpr):
    mean_auc = auc(mean_fpr, mean_tpr)
    plt.plot([0] + list(mean_fpr), [0] + list(mean_tpr), lw=2, label='ROC curve for class {} (AUC = {:.2f})'.format(class_index, mean_auc))


plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('Specificity')
plt.ylabel('Sensitivity')
plt.title('ROC curves for multiple classes using CNN')
plt.legend(loc="lower right")
plt.show()

# Initialize an empty array to store binary predictions for each class
all_pred_binary = []

# Threshold the predicted probabilities for each class separately
for class_index in range(num_classes):
    # Threshold the predicted probabilities to get the predicted labels for the current class
    y_pred_class_binary = np.argmax(y_pred_prob, axis=1)
    all_pred_binary.append(y_pred_class_binary)
    # y_pred_class_binary = (all_pred_probs[class_index] > 0.5).astype(int)
    # all_pred_binary.append(y_pred_class_binary)


# Convert the list of binary predictions to a numpy array
all_pred_binary = np.array(all_pred_binary)


# Iterate over each class and plot confusion matrix
for class_index in range(num_classes):
    # Filter true and predicted labels for the current class
    y_true_class = (y_test_encoded == class_index).astype(int)
    y_pred_class = (all_pred_binary[class_index] == class_index).astype(int)

    # Compute confusion matrix
    cm = confusion_matrix(y_true_class, y_pred_class)

    # Plot confusion matrix
    plt.figure(figsize=(4, 4))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(f'Confusion Matrix for Class {class_index}')
    plt.colorbar()

    # Manually specify tick labels for a 2x2 confusion matrix
    plt.xticks([0, 1], ['Negative', 'Positive'])
    plt.yticks([0, 1], ['Negative', 'Positive'])

    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.tight_layout()
    plt.show()

#LSTM Model

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, roc_curve, auc
from keras.models import Sequential
from keras.layers import LSTM, Dense

# Load your data
excel_file_path = 'CAR_CFD_UCFD_CRI_CARD.tsv'
column_names = ['CAR', 'CFD', 'UCFD', 'CRI', 'CARD', 'group', 'image_path', 'binary_group']
df = pd.read_csv(excel_file_path, sep='\t', names=column_names)
num_features = df[['CAR', 'CFD', 'UCFD', 'CRI', 'CARD']].values
num_features = num_features[1:]
image_paths = df['image_path'].values
image_paths = image_paths[1:]
y_string = df['group'].values[1:]

# Preprocess image data
def preprocess_image(image_path, target_size=(224, 224)):
    img = image.load_img(image_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array /= 255.0
    return img_array

images = np.array([preprocess_image(path) for path in image_paths])

# Load the VGG16 model with pretrained weights
vgg_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))
for layer in vgg_model.layers:
    layer.trainable = False
image_features = vgg_model.predict(images)

flattened_image_features = image_features.reshape(image_features.shape[0], -1)
X = np.concatenate([flattened_image_features, num_features], axis=1)

# Number of runs for averaging results
num_runs = 10

# Initialize list to store AUC values for each class
auc_values = [[] for _ in range(len(set(y_string)))]

# Parameters for model training
random_state = 42

# Reshape X for LSTM input
X = X.reshape(X.shape[0], 1, X.shape[1])

# Loop for multiple runs
for _ in range(num_runs):
    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y_string, test_size=0.3, stratify=y_string, random_state=random_state)

    # Convert class labels to numerical labels
    label_encoder = LabelEncoder()
    y_train_encoded = label_encoder.fit_transform(y_train)
    y_test_encoded = label_encoder.transform(y_test)
    num_classes = len(label_encoder.classes_)

    # Create an LSTM model
    model = Sequential()
    model.add(LSTM(64, input_shape=(1, 25093), return_sequences=True))
    model.add(LSTM(32, return_sequences=True))
    model.add(LSTM(16))
    model.add(Dense(num_classes, activation='softmax'))

    # Compile the model
    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

    # # Train the model
    # model.fit(X_train, y_train_encoded, batch_size=32, epochs=10, verbose=0)

    # model.save('LSTM_model.h5')

    # # Predict probabilities for each class
    # y_pred_prob = model.predict(X_test)

    # Calculate ROC curve and AUC for each class
    for class_index in range(num_classes):
        # Train the model
        model.fit(X_train, y_train_encoded, batch_size=32, epochs=10, verbose=0)

        model.save('LSTM_model.h5')

        # Predict probabilities for each class
        y_pred_prob = model.predict(X_test)



        y_true_binary_class = (y_test_encoded == class_index).astype(int)
        y_pred_prob_class = y_pred_prob[:, class_index]
        fpr, tpr, _ = roc_curve(y_true_binary_class, y_pred_prob_class)
        roc_auc = auc(fpr, tpr)
        auc_values[class_index].append((fpr, tpr))
        print(f"Class {class_index}: ROC AUC = {roc_auc:.2f}")

# Calculate mean ROC curve for each class
# mean_fpr_tpr = []
# for class_index in range(num_classes):
#     fpr_values = []
#     tpr_values = []
#     for fpr, tpr in auc_values[class_index]:
#         interp_tpr = np.interp(mean_fpr, fpr, tpr)
#         fpr_values.append(mean_fpr)
#         tpr_values.append(interp_tpr)
#     mean_tpr = np.mean(tpr_values, axis=0)
#     mean_auc = auc(mean_fpr, mean_tpr)
#     mean_fpr_tpr.append((mean_fpr, mean_tpr))

mean_fpr_tpr = []
for class_index in range(num_classes):
    fpr_values = []
    tpr_values = []
    max_len = 0  # Track the maximum length of FPR and TPR values among all runs
    for fpr, tpr in auc_values[class_index]:
        fpr_values.append(fpr)
        tpr_values.append(tpr)
        max_len = max(max_len, len(fpr), len(tpr))

    # Interpolate FPR and TPR values for each run to ensure they have the same length
    interp_fpr_values = [np.interp(np.linspace(0, 1, max_len), tpr, fpr) for fpr, tpr in zip(fpr_values, tpr_values)]
    interp_tpr_values = [np.interp(np.linspace(0, 1, max_len), tpr, tpr) for tpr in tpr_values]

    # Calculate mean FPR and TPR
    mean_fpr = np.mean(interp_fpr_values, axis=0)
    mean_tpr = np.mean(interp_tpr_values, axis=0)

    mean_fpr_tpr.append((mean_fpr, mean_tpr))


# Plot mean ROC curves for each class
plt.figure(figsize=(8, 6))
for class_index, (mean_fpr, mean_tpr) in enumerate(mean_fpr_tpr):
    mean_auc = auc(mean_fpr, mean_tpr)
    plt.plot([0] + list(mean_fpr), [0] + list(mean_tpr), lw=2, label='ROC curve for class {} (AUC = {:.2f})'.format(class_index, mean_auc))

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('Specificity')
plt.ylabel('Sensitivity')
plt.title('ROC curves for multiple classes using LSTM')
plt.legend(loc="lower right")
plt.show()

# Initialize an empty array to store binary predictions for each class
all_pred_binary = []

# Threshold the predicted probabilities for each class separately
for class_index in range(num_classes):
    # Threshold the predicted probabilities to get the predicted labels for the current class
    y_pred_class_binary = np.argmax(y_pred_prob, axis=1)
    all_pred_binary.append(y_pred_class_binary)


# Convert the list of binary predictions to a numpy array
all_pred_binary = np.array(all_pred_binary)



# Iterate over each class and plot confusion matrix
for class_index in range(num_classes):
    # Filter true and predicted labels for the current class
    y_true_class = (y_test_encoded == class_index).astype(int)
    y_pred_class = (all_pred_binary[class_index] == class_index).astype(int)

    # Compute confusion matrix
    cm = confusion_matrix(y_true_class, y_pred_class)

    # Plot confusion matrix
    plt.figure(figsize=(4, 4))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(f'Confusion Matrix for Class {class_index}')
    plt.colorbar()

    # Manually specify tick labels for a 2x2 confusion matrix
    plt.xticks([0, 1], ['Negative', 'Positive'])
    plt.yticks([0, 1], ['Negative', 'Positive'])

    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.tight_layout()
    plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, roc_curve, auc
from keras.models import Sequential
from keras.layers import Dense

# Load your data
excel_file_path = 'CAR_CFD_UCFD_CRI_CARD.tsv'
column_names = ['CAR', 'CFD', 'UCFD', 'CRI', 'CARD', 'group', 'image_path', 'binary_group']
df = pd.read_csv(excel_file_path, sep='\t', names=column_names)
num_features = df[['CAR', 'CFD', 'UCFD', 'CRI', 'CARD']].values
num_features = num_features[1:]
image_paths = df['image_path'].values
image_paths = image_paths[1:]
y_string = df['group'].values[1:]

# Preprocess image data
def preprocess_image(image_path, target_size=(224, 224)):
    img = image.load_img(image_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array /= 255.0
    return img_array

images = np.array([preprocess_image(path) for path in image_paths])

# Load the VGG16 model with pretrained weights
vgg_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))
for layer in vgg_model.layers:
    layer.trainable = False
image_features = vgg_model.predict(images)

flattened_image_features = image_features.reshape(image_features.shape[0], -1)
X = np.concatenate([flattened_image_features, num_features], axis=1)

# Number of runs for averaging results
num_runs = 10

# Initialize list to store AUC values for each class
auc_values = [[] for _ in range(len(set(y_string)))]

# Parameters for model training
random_state = 42

# Reshape X for autoencoder input
X = X.reshape(X.shape[0], -1)

# Loop for multiple runs
for _ in range(num_runs):
    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y_string, test_size=0.3, stratify=y_string, random_state=random_state)

    # Convert class labels to numerical labels
    label_encoder = LabelEncoder()
    y_train_encoded = label_encoder.fit_transform(y_train)
    y_test_encoded = label_encoder.transform(y_test)
    num_classes = len(label_encoder.classes_)

    # Create an autoencoder-decoder model
    model = Sequential()
    model.add(Dense(64, activation='relu', input_shape=(X.shape[1],)))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(16, activation='relu'))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(X.shape[1], activation='sigmoid'))

    # Compile the model
    model.compile(loss='mean_squared_error', optimizer='adam')



    # Calculate ROC curve and AUC for each class
    for class_index in range(num_classes):
        # Train the model
        model.fit(X_train, X_train, batch_size=32, epochs=10, verbose=0)
        # Encode and decode the test data
        encoded_X_test = model.predict(X_test)


        y_true_binary_class = (y_test_encoded == class_index).astype(int)
        y_pred_prob_class = y_pred_prob[:, class_index]
        fpr, tpr, _ = roc_curve(y_true_binary_class, y_pred_prob_class)
        roc_auc = auc(fpr, tpr)
        auc_values[class_index].append((fpr, tpr))
        print(f"Class {class_index}: ROC AUC = {roc_auc:.2f}")

model.save('Autoencoder_decoder_model.h5')

# Calculate mean ROC curve for each class
mean_fpr_tpr = []
for class_index in range(num_classes):
    fpr_values = []
    tpr_values = []
    max_len = 0  # Track the maximum length of FPR and TPR values among all runs
    for fpr, tpr in auc_values[class_index]:
        fpr_values.append(fpr)
        tpr_values.append(tpr)
        max_len = max(max_len, len(fpr), len(tpr))

    # Interpolate FPR and TPR values for each run to ensure they have the same length
    interp_fpr_values = [np.interp(np.linspace(0, 1, max_len), tpr, fpr) for fpr, tpr in zip(fpr_values, tpr_values)]
    interp_tpr_values = [np.interp(np.linspace(0, 1, max_len), tpr, tpr) for tpr in tpr_values]

    # Calculate mean FPR and TPR
    mean_fpr = np.mean(interp_fpr_values, axis=0)
    mean_tpr = np.mean(interp_tpr_values, axis=0)

    mean_fpr_tpr.append((mean_fpr, mean_tpr))

# Plot mean ROC curves for each class
plt.figure(figsize=(8, 6))
for class_index, (mean_fpr, mean_tpr) in enumerate(mean_fpr_tpr):
    mean_auc = auc(mean_fpr, mean_tpr)
    plt.plot([0] + list(mean_fpr), [0] + list(mean_tpr), lw=2, label='ROC curve for class {} (AUC = {:.2f})'.format(class_index, mean_auc))

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('Specificity')
plt.ylabel('Sensitivity')
plt.title('ROC curves for multiple classes using AutoEncoder Decoder')
plt.legend(loc="lower right")
plt.show()

# Initialize an empty array to store binary predictions for each class
all_pred_binary = []

# Threshold the reconstruction error for each class separately
for class_index in range(num_classes):

    # Reconstruction error as the prediction
    # y_pred_prob_class = np.linalg.norm(X_test - encoded_X_test, axis=1)
    # # Threshold the reconstruction error to get the predicted labels for the current class
    # threshold = np.percentile(y_pred_prob_class, 95)  # Example threshold (adjust as needed)
    # y_pred_class_binary = (y_pred_prob_class > threshold).astype(int)
    # all_pred_binary.append(y_pred_class_binary)
    y_pred_class_binary = np.argmax(y_pred_prob, axis=1)
    all_pred_binary.append(y_pred_class_binary)

# Convert the list of binary predictions to a numpy array
all_pred_binary = np.array(all_pred_binary)

# Iterate over each class and plot confusion matrix
for class_index in range(num_classes):
    # Filter true and predicted labels for the current class
    y_true_class = (y_test_encoded == class_index).astype(int)
    y_pred_class = (all_pred_binary[class_index] == class_index).astype(int)

    # Compute confusion matrix
    cm = confusion_matrix(y_true_class, y_pred_class)

    # Plot confusion matrix
    plt.figure(figsize=(4, 4))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(f'Confusion Matrix for Class {class_index}')
    plt.colorbar()

    # Manually specify tick labels for a 2x2 confusion matrix
    plt.xticks([0, 1], ['Negative', 'Positive'])
    plt.yticks([0, 1], ['Negative', 'Positive'])

    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.tight_layout()
    plt.show()

print("Data types of X_test and encoded_X_test:")
print("X_test:", X_test.dtype)
print("encoded_X_test:", encoded_X_test.dtype)







X_normalized.shape



X.shape

import pandas as pd
import plotly.express as px

# Your data
data = {
    # 'category': ['nonARG', 'beta-lactam', 'peptide', 'multidrug', 'aminoglycoside',
    #              'MLS', 'tetracycline', 'fluoroquinolone',
    #              'antibiotic', 'phenicol', 'glycopeptide', 'aminocoumarin', 'diaminopyrimidine',
    #              'nitroimidazole', 'rifamycin', 'sulfonamide', 'polymyxin', 'disinfecting',
    #              'elfamycin', 'nucleoside', 'oxazolidinone', 'chloramphenicol', 'phosphonic',
    #              'pleuromutilin', 'polyamine', 'quinolone', 'tetracenomycin', 'polypeptide',
    #              'bicyclomycin-like', 'alkaloids', 'nitrofuran', 'antibacterial', 'ionophore'],
    'category': ['In utero Air(Control)', 'In utero SHS(Baseline)', 'In utero Air + Urethane(Treatment_1)', 'In utero SHS + Urethane(Treatment_2)'],
    # 'pop': [27041, 9169, 5551, 5528, 2634, 2564, 1358, 1254, 939, 589, 551, 244, 213, 117,
    #         102, 96, 47, 42, 32, 23, 22, 22, 12, 9, 8, 8, 8, 7, 5, 3, 2, 2, 2] (Control)  (Baseline)  (Cancer Treatment_03)  (Cancer Treatment_04)
    'pop': [13, 12, 12, 12]
}

# Create DataFrame
df = pd.DataFrame(data)

# Plot
fig = px.pie(df, values='pop', names='category')
fig.update_traces(
    textposition='outside',
    textinfo='percent+label',
    textfont_size=18
)
fig.update_layout(
    width=1000,
    height=400
)
fig.show()

import pandas as pd
import plotly.express as px

# Your data
data = {
    'category': ['In utero Air (Control)', 'In utero SHS (Baseline)', 'In utero Air + Urethane (Treatment_1)', 'In utero SHS + Urethane (Treatment_2)'],
    'pop': [13, 12, 12, 12]
}

# Create DataFrame
df = pd.DataFrame(data)

# Plot
fig = px.pie(df, values='pop', names='category')

fig.update_traces(
    textposition='outside',
    textinfo='percent+label',
    textfont_size=18,
    #outsidetextfont='black'
)
fig.update_traces(
    outsidetextfont=dict(color='black')
)
fig.update_layout(
    width=1000,
    height=400,
    legend=dict(
        x=1,
        y=0.5,
        traceorder='normal',
        font=dict(
            family='Arial',
            size=18,
            color='black'
        ),
        bgcolor='white',
        bordercolor='Black',
        borderwidth=2
    )
)
fig.show()

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Load the data
data = pd.read_csv("CAR_CFD_UCFD_CRI_CARD.tsv", sep="\t")

# Step 2: Standardize the data
scaler = StandardScaler()
scaled_data = scaler.fit_transform(data.drop(columns=['Id', 'group', 'image_path', 'binary_group']))

# Step 3: Apply PCA
pca = PCA()
pca.fit(scaled_data)

# Step 4: Plot Scree Plot with column names on x-axis
# plt.figure(figsize=(10, 6))
# plt.plot(range(1, pca.n_components_ + 1), pca.explained_variance_ratio_, marker='o', linestyle='-')
# plt.title('Scree Plot of PCA')
# plt.xlabel('Principal Component')
# plt.ylabel('Explained Variance Ratio')
# plt.xticks(range(1, pca.n_components_ + 1))
# plt.grid(True)
# plt.show()

plt.figure(figsize=(10, 6))
plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_, marker='o', linestyle='-')
plt.title('Scree Plot of PCA', fontsize=16)
plt.xlabel('Principal Component', fontsize=14)
plt.ylabel('Explained Variance Ratio', fontsize=14)
plt.xticks(range(1, len(pca.explained_variance_ratio_) + 1))
plt.grid(True)
plt.show()

# # Step 4: Plot Scree Plot with column names on x-axis
# plt.figure(figsize=(10, 6))
# plt.plot(pca_components.columns, pca.explained_variance_ratio_, marker='o', linestyle='-')
# plt.title('Scree Plot of PCA', fontsize=16)
# plt.xlabel('Principal Component', fontsize=14)
# plt.ylabel('Explained Variance Ratio', fontsize=14)
# plt.xticks()
# plt.grid(True)
# plt.show()


# Step 5: Correlation Matrix of PCA
# Step 5: Correlation Matrix of PCA
# pca_components = pd.DataFrame(pca.components_.T, columns=[f'PC{i+1}' for i in range(pca.n_components_)])
# corr_matrix = pca_components.corr()

# plt.figure(figsize=(10, 8))
# sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", annot_kws={"size": 10}, vmin=-1, vmax=1)
# plt.title('Correlation Matrix of PCA Components', fontsize=16)
# plt.show()
pca_components = pd.DataFrame(pca.components_.T, columns=[f'PC{i+1}' for i in range(pca.n_components_)])
corr_matrix = pca_components.corr()

# Define the desired order of PC labels
pc_labels = [f'PC{i+1}' for i in range(pca.n_components_)]

# Plot the correlation matrix heatmap with reversed Y-axis labels
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", annot_kws={"size": 10},
            xticklabels=pc_labels, yticklabels=pc_labels[::-1])
plt.title('Correlation Matrix of PCA Components', fontsize=16)
plt.show()

# Step 6: t-SNE Visualization of PC1 vs PC2
tsne = TSNE(n_components=2, perplexity=30, random_state=42)
pca_result = pca.transform(scaled_data)
tsne_result = tsne.fit_transform(pca_result)

plt.figure(figsize=(10, 8))
sns.scatterplot(x=tsne_result[:,0], y=tsne_result[:,1], hue=data['group'], palette='Set1')
plt.title('t-SNE Visualization of PC1 vs PC2')
plt.xlabel('PC1')
plt.ylabel('PC2')
plt.legend(title='Group')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans

# Step 1: Load the Dataset
data = pd.read_csv("CAR_CFD_UCFD_CRI_CARD.tsv", sep="\t")

# Step 2: Data Exploration and Visualization
# Explore the dataset and visualize relevant features
# For example, you can use pairplot to visualize pairwise relationships
sns.pairplot(data, vars=["CAR", "CRI"], hue="group")
plt.title('Pairplot of Relevant Features')
plt.show()

# Step 3: K-means Clustering
# Perform K-means clustering on relevant features
# For example, let's perform K-means on CAR and CRI
kmeans = KMeans(n_clusters=2, random_state=42)
data['cluster'] = kmeans.fit_predict(data[['CAR', 'CRI']])

# Visualize the clusters
plt.figure(figsize=(8, 6))
sns.scatterplot(data=data, x='CRI', y='CAR', hue='cluster', palette='viridis', legend='full')
plt.title('K-means Clustering of CAR vs CRI')
plt.xlabel('CRI')
plt.ylabel('CAR')
plt.show()

# Step 4: Average Distribution of Collagen
# Calculate the average distribution of collagen based on the provided information
# For example, you can calculate the mean CAR for each group
average_distribution = data.groupby('group')['CAR'].mean().reset_index()

# Visualize the average distribution of collagen
plt.figure(figsize=(10, 6))
sns.barplot(data=average_distribution, x='group', y='CAR', palette='Set1')
plt.title('Average Distribution of Collagen in Lung Tissue')
plt.xlabel('Group')
plt.ylabel('Average CAR')
plt.xticks(rotation=45)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans

# Step 1: Load the Dataset
data = pd.read_csv("CAR_CFD_UCFD_CRI_CARD.tsv", sep="\t")

# Step 2: Perform K-means clustering and visualize for each group
plt.figure(figsize=(10, 6))

# Define a palette with enough distinct colors for each group
palette = sns.color_palette("husl", n_colors=len(data['group'].unique()))

# Iterate over each group
for i, group in enumerate(data['group'].unique()):
    # Filter data for the current group
    group_data = data[data['group'] == group]

    # Perform K-means clustering on CRI and CAR for the current group
    kmeans = KMeans(n_clusters=2, random_state=42)
    group_data['cluster'] = kmeans.fit_predict(group_data[['CRI', 'CAR']])

    # Visualize the clusters for the current group
    sns.scatterplot(data=group_data, x='CRI', y='CAR', hue='group', palette=palette[i:i+1], legend='full', s=77)

#plt.title('K-means Clustering of CRI vs CAR for Different Groups', fontsize = 16)
plt.xlabel('Collagen Reticulation Index', fontsize = 14)
plt.ylabel('Collagen Area Ratio', fontsize = 14)
plt.legend(title='Group', loc='upper left', bbox_to_anchor=(0, 1))

plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans

# Step 1: Load the Dataset
data = pd.read_csv("CAR_CFD_UCFD_CRI_CARD.tsv", sep="\t")

# Step 2: Perform K-means clustering and visualize for each group
plt.figure(figsize=(10, 6))

# Define a palette with enough distinct colors for each group
palette = sns.color_palette("husl", n_colors=len(data['group'].unique()))

# Iterate over each group
for i, group in enumerate(data['group'].unique()):
    # Filter data for the current group
    group_data = data[data['group'] == group]

    # Perform K-means clustering on CRI and CAR for the current group
    kmeans = KMeans(n_clusters=1, random_state=42)  # Only 1 cluster for each group
    centroid = kmeans.fit(group_data[['CRI', 'CAR']]).cluster_centers_[0]  # Get the centroid

    # Visualize the centroid for the current group
    sns.scatterplot(x=[centroid[0]], y=[centroid[1]], color=palette[i], label=group, s=700, marker='o')

#plt.title('K-means Clustering of CRI vs CAR for Different Groups', fontsize=16)
plt.xlabel('Collagen Reticulation Index', fontsize=14)
plt.ylabel('Collagen Area Ratio', fontsize=14)

# Manually adjust the legend position to avoid overlap and reduce marker size
plt.legend(title='Group', loc='upper left', bbox_to_anchor=(0, 1), markerscale=0.5)

plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
import umap

# Load the dataset
data = pd.read_csv("CAR_CFD_UCFD_CRI_CARD.tsv", sep="\t")

# Compute T-SNE embedding
tsne = TSNE(n_components=2, random_state=42)
tsne_result = tsne.fit_transform(data.drop(columns=['Id', 'image_path', 'binary_group', 'group']))

# Compute UMAP embedding
umap_result = umap.UMAP(n_components=2, random_state=42).fit_transform(data.drop(columns=['Id', 'image_path', 'binary_group', 'group']))

# Plot T-SNE
plt.figure(figsize=(10, 5))

sns.scatterplot(x=tsne_result[:, 0], y=tsne_result[:, 1], hue=data['group'], palette='Set1')
#plt.title('T-SNE', fontsize = 14)
plt.xlabel('t-SNE 1', fontsize = 14)
plt.ylabel('t-SNE 2', fontsize = 14)
plt.legend(title='Group')
plt.show()

# Plot UMAP

plt.figure(figsize=(10, 5))
sns.scatterplot(x=umap_result[:, 0], y=umap_result[:, 1], hue=data['group'], palette='Set1')
#plt.title('UMAP')
plt.xlabel('UMAP 1', fontsize = 14)
plt.ylabel('UMAP 2', fontsize = 14)
plt.legend(title='Group')

#plt.tight_layout()
plt.show()

# Calculate features for each collagen image summed across all polarization states
# For example, let's say your dataset has columns 'Standard Error', 'P-value', 'Confidence Interval', 'x', and 'y'
# features = data.groupby('image_path').agg({
#     'Standard Error': 'sum',
#     'P-value': 'sum',
#     'Confidence Interval': 'sum',
#     'x': 'mean',
#     'y': 'mean'
# }).reset_index()

# print(features)

import pandas as pd
from sklearn.manifold import TSNE
import umap

# Load the dataset
data = pd.read_csv("CAR_CFD_UCFD_CRI_CARD.tsv", sep="\t")

# Compute T-SNE embedding
tsne = TSNE(n_components=5, random_state=42)
tsne_result = tsne.fit_transform(data.drop(columns=['Id', 'image_path', 'binary_group', 'group']))

# Compute UMAP embedding
umap_result = umap.UMAP(n_components=5, random_state=42).fit_transform(data.drop(columns=['Id', 'image_path', 'binary_group', 'group']))

# Print T-SNE results
print("T-SNE Results:")
print(tsne_result)

# Print UMAP results
print("\nUMAP Results:")
print(umap_result)

!pip install umap-learn

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import sem

# Load the dataset
data = pd.read_csv("Data_SHG_FINAL.tsv", sep="\t")

# Group the data by the 'group' column
grouped_data = data.groupby('group')['Collagen%Transformedimage((Red+pink)/Total)']

# Calculate statistics for each group
group_stats = grouped_data.agg(['mean', 'std', sem])  # mean, standard deviation, standard error
group_stats['p_value'] = 0.05  # Assuming a constant p-value of 0.05 for illustration

# Plot the distribution of 'CAR' for each group
# plt.figure(figsize=(10, 6))
# for group_name, group_values in grouped_data:
#     sns.histplot(group_values, kde=True, label=group_name)

# plt.title('Distribution of CAR for Different Groups')
# plt.xlabel('CAR')
# plt.ylabel('Frequency')
# plt.legend(title='Group')
# plt.show()

plt.figure(figsize=(12, 8))
sns.boxplot(data=data, x='group', y='Collagen%Transformedimage((Red+pink)/Total)', palette='Set1')
plt.title('Distribution of Collagen (%) Across Different Groups', fontsize = 16)
plt.xlabel('', fontsize = 14)
plt.ylabel('Lung fibrillar collagen (%)', fontsize = 14)
plt.xticks(rotation=0)  # Rotate x-axis labels for better visibility
plt.tick_params(axis='x', labelsize=14)
plt.show()

# plt.figure(figsize=(10, 6))
# sns.histplot(data=data, x='Collagen%_Transformed_image_((Red+pink)/Total)', hue='group', kde=True, palette='Set1', bins=20)
# plt.title('Distribution of CAR for Different Groups')
# plt.xlabel('CAR')
# plt.ylabel('Frequency')
# plt.legend(title='Group')
# plt.show()

# Print the calculated statistics
print("Statistics for CAR column:")
print(group_stats)



import pandas as pd

# Load the Excel file
excel_file = 'CAR_CFD_UCFD_CRI_CARD.xlsx'
df = pd.read_excel(excel_file)

# Save the DataFrame to a TSV file
tsv_file = 'CAR_CFD_UCFD_CRI_CARD.tsv'
df.to_csv(tsv_file, sep='\t', index=False)

data







import pandas as pd
import plotly.express as px

# Your data
data = {
    'category': ['nonARG', 'beta-lactam', 'peptide', 'multidrug', 'aminoglycoside',
                 'MLS', 'tetracycline', 'fluoroquinolone',
                 'antibiotic', 'phenicol', 'glycopeptide', 'aminocoumarin', 'diaminopyrimidine',
                 'nitroimidazole', 'rifamycin', 'sulfonamide', 'polymyxin', 'disinfecting',
                 'elfamycin', 'nucleoside', 'oxazolidinone', 'chloramphenicol', 'phosphonic',
                 'pleuromutilin', 'polyamine', 'quinolone', 'tetracenomycin', 'polypeptide',
                 'bicyclomycin-like', 'alkaloids', 'nitrofuran', 'antibacterial', 'ionophore'],
    #'category': ['In utero Air(Control)', 'In utero SHS(Baseline)', 'In utero Air + Urethane(Treatment_1)', 'In utero SHS + Urethane(Treatment_2)'],
    'pop': [27041, 9169, 5551, 5528, 2634, 2564, 1358, 1254, 939, 589, 551, 244, 213, 117,
            102, 96, 47, 42, 32, 23, 22, 22, 12, 9, 8, 8, 8, 7, 5, 3, 2, 2, 2]
    #'pop': [13, 12, 12, 12]
}

# Create DataFrame
df = pd.DataFrame(data)

# Plot
fig = px.pie(df, values='pop', names='category')
fig.update_traces(
    textposition='inside',
    textinfo='percent+label',
    textfont_size=18
)
fig.update_layout(
    width=1000,
    height=800
)
fig.show()

